{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96cecbb1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-07-14T18:47:01.028139Z",
     "iopub.status.busy": "2023-07-14T18:47:01.027292Z",
     "iopub.status.idle": "2023-07-14T18:47:11.028359Z",
     "shell.execute_reply": "2023-07-14T18:47:11.027346Z"
    },
    "papermill": {
     "duration": 10.009744,
     "end_time": "2023-07-14T18:47:11.031016",
     "exception": false,
     "start_time": "2023-07-14T18:47:01.021272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# First we will import neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2 as cv\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Lambda\n",
    "from tqdm import tqdm\n",
    "import albumentations as A \n",
    "import shutil\n",
    "import skimage\n",
    "from skimage.transform import  resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc031ae3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:47:11.042075Z",
     "iopub.status.busy": "2023-07-14T18:47:11.041198Z",
     "iopub.status.idle": "2023-07-14T18:47:25.409408Z",
     "shell.execute_reply": "2023-07-14T18:47:25.408386Z"
    },
    "papermill": {
     "duration": 14.376235,
     "end_time": "2023-07-14T18:47:25.411974",
     "exception": false,
     "start_time": "2023-07-14T18:47:11.035739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to the dataset directory\n",
    "dataset_dir = '/kaggle/input/dangerous-insects-dataset/farm_insects'\n",
    "\n",
    "# Output directory for train and test sets\n",
    "output_dir = '/kaggle/working/dataset'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "test_dir = os.path.join(output_dir, 'test')\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Splitting the dataset into train and test sets\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, class_name)\n",
    "    images = os.listdir(class_dir)\n",
    "    \n",
    "    # Split images into train and test sets\n",
    "    train_images, test_images = train_test_split(images, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Create class directories in train and test sets\n",
    "    class_train_dir = os.path.join(train_dir, class_name)\n",
    "    class_test_dir = os.path.join(test_dir, class_name)\n",
    "    os.makedirs(class_train_dir, exist_ok=True)\n",
    "    os.makedirs(class_test_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy images to their respective directories\n",
    "    for image in train_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dst = os.path.join(class_train_dir, image)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    for image in test_images:\n",
    "        src = os.path.join(class_dir, image)\n",
    "        dst = os.path.join(class_test_dir, image)\n",
    "        shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff46d98f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:47:25.422761Z",
     "iopub.status.busy": "2023-07-14T18:47:25.422426Z",
     "iopub.status.idle": "2023-07-14T18:51:30.638852Z",
     "shell.execute_reply": "2023-07-14T18:51:30.637751Z"
    },
    "papermill": {
     "duration": 245.240404,
     "end_time": "2023-07-14T18:51:30.656993",
     "exception": false,
     "start_time": "2023-07-14T18:47:25.416589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the balanced dataset will be saved to /kaggle/working/balanced dataset\n",
      "the dataset will be balanced to have 220 image files in each class\n",
      "processing files in train directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Africanized Honey Bees (K: 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 67/67 [00:01<00:00, 44.76files/s]\u001b[0m\n",
      "Aphids                   : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 61/61 [00:01<00:00, 40.50files/s]\u001b[0m\n",
      "Armyworms                : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 67/67 [00:00<00:00, 80.21files/s]\u001b[0m\n",
      "Brown Marmorated Stink Bu:  14%|\u001b[34m███████▍                                             \u001b[0m| 11/79 [00:00<00:00, 95.48files/s]\u001b[0m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Brown Marmorated Stink Bu: 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 79/79 [00:01<00:00, 42.45files/s]\u001b[0m\n",
      "Cabbage Loopers          : 100%|\u001b[34m████████████████████████████████████████████████████\u001b[0m| 72/72 [00:00<00:00, 118.67files/s]\u001b[0m\n",
      "Citrus Canker            : 100%|\u001b[34m████████████████████████████████████████████████████\u001b[0m| 72/72 [00:00<00:00, 102.79files/s]\u001b[0m\n",
      "Colorado Potato Beetles  : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 78/78 [00:00<00:00, 79.45files/s]\u001b[0m\n",
      "Corn Borers              : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 80/80 [00:00<00:00, 95.64files/s]\u001b[0m\n",
      "Corn Earworms            : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 77/77 [00:01<00:00, 62.66files/s]\u001b[0m\n",
      "Fall Armyworms           : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 79/79 [00:01<00:00, 69.83files/s]\u001b[0m\n",
      "Fruit Flies              : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 70/70 [00:00<00:00, 74.22files/s]\u001b[0m\n",
      "Spider Mites             : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 83/83 [00:01<00:00, 48.02files/s]\u001b[0m\n",
      "Thrips                   : 100%|\u001b[34m████████████████████████████████████████████████████\u001b[0m| 76/76 [00:00<00:00, 105.66files/s]\u001b[0m\n",
      "Tomato Hornworms         : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 76/76 [00:01<00:00, 68.23files/s]\u001b[0m\n",
      "Western Corn Rootworms   : 100%|\u001b[34m█████████████████████████████████████████████████████\u001b[0m| 70/70 [00:00<00:00, 73.11files/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average height of the images= 762 the average_width of the images = 1021\n",
      "the dataset has 15 classes listed below:\n",
      " File Count                     Class                    \n",
      "     61                        Aphids                    \n",
      "     67         Africanized Honey Bees (Killer Bees)     \n",
      "     67                       Armyworms                  \n",
      "     70                      Fruit Flies                 \n",
      "     70                Western Corn Rootworms            \n",
      "     72                    Cabbage Loopers               \n",
      "     72                     Citrus Canker                \n",
      "     76                        Thrips                    \n",
      "     76                   Tomato Hornworms               \n",
      "     77                     Corn Earworms                \n",
      "     78                Colorado Potato Beetles           \n",
      "     79              Brown Marmorated Stink Bugs         \n",
      "     79                    Fall Armyworms                \n",
      "     80                      Corn Borers                 \n",
      "     83                     Spider Mites                 \n",
      "class Spider Mites has the most image files= 83, class Aphids has the least images= 61\n",
      "creating 159 augmented images for class Aphids\n",
      "creating 153 augmented images for class Africanized Honey Bees (Killer Bees)\n",
      "creating 153 augmented images for class Armyworms\n",
      "creating 150 augmented images for class Fruit Flies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/877597905.py:116: UserWarning: /kaggle/working/dummy/Fruit Flies/aug-83-Image_12.jpg is a low contrast image\n",
      "  skimage.io.imsave(dummy_fpath, aug_img)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 150 augmented images for class Western Corn Rootworms\n",
      "creating 148 augmented images for class Cabbage Loopers\n",
      "creating 148 augmented images for class Citrus Canker\n",
      "creating 144 augmented images for class Thrips\n",
      "creating 144 augmented images for class Tomato Hornworms\n",
      "creating 143 augmented images for class Corn Earworms\n",
      "creating 142 augmented images for class Colorado Potato Beetles\n",
      "creating 141 augmented images for class Brown Marmorated Stink Bugs\n",
      "creating 141 augmented images for class Fall Armyworms\n",
      "creating 140 augmented images for class Corn Borers\n",
      "creating 137 augmented images for class Spider Mites\n",
      "the balanced dataset with 220 image files in each class is stored in /kaggle/working/balanced dataset \n"
     ]
    }
   ],
   "source": [
    "sdir=('/kaggle/working/dataset/train')\n",
    "working_dir=('/kaggle/working')\n",
    "dest_dir=os.path.join(working_dir, 'balanced dataset')\n",
    "print(f'the balanced dataset will be saved to {dest_dir}')\n",
    "if os.path.isdir(dest_dir):\n",
    "    shutil.rmtree(dest_dir) # start with a clean empty dest_dir\n",
    "os.mkdir(dest_dir) \n",
    "limiter=int(220)\n",
    "print(f'the dataset will be balanced to have {limiter} image files in each class')\n",
    "print(f'processing files in train directory')\n",
    "classes=sorted(os.listdir(sdir))# make a list of the classes\n",
    "class_count=len(classes)# number of classes\n",
    "bad_img_list=[]\n",
    "ht=0\n",
    "wt=0\n",
    "good_file_count=0\n",
    "for klass in classes: # iterate through the classes\n",
    "    classpath=os.path.join(sdir,klass)\n",
    "    dest_classpath=os.path.join(dest_dir, klass)\n",
    "    os.mkdir(dest_classpath) # make a directory in the dest_dir for this class\n",
    "    flist=sorted(os.listdir(classpath))# get list of files in each class    \n",
    "    fcount=len(flist) \n",
    "    if fcount>limiter: # if the number of files is greator than the limiter sample the file list to have limiter number of files\n",
    "        flist=np.random.choice(flist, limiter, replace=False)      \n",
    "    desc=f'{klass[:25]:25s}' # show which class is being procesed\n",
    "    for f in tqdm(flist, ncols=120, colour='blue', desc=desc, unit='files'): # iterate through the files in each class\n",
    "        fpath=os.path.join(classpath,f)\n",
    "        dest_fpath=os.path.join(dest_classpath, f) # where to store the file\n",
    "        try: # test if the image file can be read if so save it to the dest_dir\n",
    "            img= skimage.io.imread(fpath)            \n",
    "            shape=img.shape \n",
    "            ht += shape[0]\n",
    "            wt += shape[1]\n",
    "            good_file_count +=1\n",
    "            shutil.copy(fpath,  dest_fpath)  \n",
    "        except: # if the image file can not be read store the path in the bad_img_list\n",
    "            bad_img_list.append(fpath)\n",
    "if len(bad_img_list)>0:\n",
    "    print(f'the image files listed below could not be processed and were not included in the balanced dataset')\n",
    "    for f in bad_img_list:\n",
    "        print (f)\n",
    "have=int(ht/good_file_count)\n",
    "wave=int(wt/good_file_count)\n",
    "print(f'the average height of the images= {have} the average_width of the images = {wave}')\n",
    "# some files in the original dataset may have been invalid image files and were not copied to the destination directory\n",
    "# so go through the destination directory and determine how many files are in each class and store in fcount_list\n",
    "\n",
    "classes=sorted(os.listdir(dest_dir))\n",
    "fcount_list=[]# list to store how many files are in each class\n",
    "for klass in classes:\n",
    "    classpath=os.path.join(dest_dir, klass)\n",
    "    flist=sorted(os.listdir(classpath))\n",
    "    file_count=len(flist)\n",
    "    fcount_list.append(file_count)\n",
    "zip_list=zip(fcount_list,classes)\n",
    "ordered_list=sorted(zip_list) # order the list by the number of files\n",
    "fc='File Count'\n",
    "k='Class'\n",
    "print(f'the dataset has {class_count} classes listed below:')\n",
    "print(f'{fc:^12s}{k:^45s}')\n",
    "classes=[]\n",
    "fcount=[]\n",
    "for count, klass in ordered_list:\n",
    "    fcount.append(count)\n",
    "    classes.append(klass)\n",
    "    strcount=str(count)\n",
    "    print(f'{strcount:^12s}{klass:^45s}')\n",
    "min_class=classes[0]\n",
    "min_count=fcount[0]\n",
    "length=len(classes)-1\n",
    "max_class=classes[length]\n",
    "max_count=fcount[length]\n",
    "print(f'class {max_class} has the most image files= {max_count}, class {min_class} has the least images= {min_count}')\n",
    "# lets define a function that creates an augmented image\n",
    "\n",
    "def get_augmented_image(image): # given an image this function returns an augmented image\n",
    "    width=int(image.shape[1]*.8)\n",
    "    height=int(image.shape[0]*.8)\n",
    "    transform= A.Compose([\n",
    "        A.HorizontalFlip(p=.5),\n",
    "        A.Rotate(limit=30, p=.25),\n",
    "        A.RandomBrightnessContrast(p=.5),\n",
    "        A.RandomGamma(p=.5),\n",
    "        A.RandomCrop(width=width, height=height, p=.25) ])    \n",
    "    return transform(image=image)['image']\n",
    "\n",
    "# Iterate through the classes, for a class with less than limiter number image files create augmented images\n",
    "# so each class has limiter number of image files\n",
    "no_save_list=[]\n",
    "dummy_path=os.path.join(working_dir, 'dummy')\n",
    "if os.path.isdir(dummy_path):\n",
    "    shutil.rmtree(dummy_path)\n",
    "os.mkdir(dummy_path)\n",
    "for count, klass in ordered_list:\n",
    "    aug_counter=0\n",
    "    i= -1\n",
    "    if count < limiter: # if this class has less than the limiter value of files\n",
    "        delta=limiter - count # this is how many augmented images we need to create for this class\n",
    "        print (f'creating {delta} augmented images for class {klass}')\n",
    "        classpath=os.path.join(dest_dir,klass)# path to class\n",
    "        dest_classpath=os.path.join(dest_dir,klass) # where to store files for this class  \n",
    "        dummy_classpath=os.path.join(dummy_path, klass)\n",
    "        os.mkdir(dummy_classpath)\n",
    "        flist=sorted(os.listdir(classpath))# get list of files for this class         \n",
    "        while aug_counter<delta:\n",
    "            i +=1 \n",
    "            j=i % count # delta may be greator than the number of files in the class so use mod of count as file indexer\n",
    "            fpath=os.path.join(classpath, flist[j]) # path to the image file to augment\n",
    "            \n",
    "            # give the augmented image a unique file name\n",
    "            dest_fpath=os.path.join(dest_classpath,'aug-'+str(i)+'-'+ flist[j])# path of where to store the augmented image\n",
    "            dummy_fpath=os.path.join(dummy_classpath,'aug-'+str(i)+'-'+ flist[j])\n",
    "            try:                \n",
    "                img= skimage.io.imread(fpath)\n",
    "                aug_img=get_augmented_image(img) # augment the image \n",
    "                skimage.io.imsave(dummy_fpath, aug_img)\n",
    "                skimage.io.imsave(dest_fpath, aug_img) # save the augmented image\n",
    "                aug_counter +=1\n",
    "            except:\n",
    "                no_save_list.append(fpath)\n",
    "print(f'the balanced dataset with {limiter} image files in each class is stored in {dest_dir} ') \n",
    "shutil.rmtree(dummy_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de93e1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:51:30.692447Z",
     "iopub.status.busy": "2023-07-14T18:51:30.692120Z",
     "iopub.status.idle": "2023-07-14T18:51:30.699769Z",
     "shell.execute_reply": "2023-07-14T18:51:30.698928Z"
    },
    "papermill": {
     "duration": 0.027413,
     "end_time": "2023-07-14T18:51:30.701772",
     "exception": false,
     "start_time": "2023-07-14T18:51:30.674359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = \"/kaggle/working/balanced dataset\"\n",
    "key_value= dict()\n",
    "for i in os.listdir(path):\n",
    "    key_value[i] = os.listdir(path+'/'+i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18ecb0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:51:30.739197Z",
     "iopub.status.busy": "2023-07-14T18:51:30.738395Z",
     "iopub.status.idle": "2023-07-14T18:51:30.764222Z",
     "shell.execute_reply": "2023-07-14T18:51:30.763309Z"
    },
    "papermill": {
     "duration": 0.044978,
     "end_time": "2023-07-14T18:51:30.766173",
     "exception": false,
     "start_time": "2023-07-14T18:51:30.721195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cabbage Loopers</td>\n",
       "      <td>/kaggle/working/balanced dataset/Cabbage Loope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cabbage Loopers</td>\n",
       "      <td>/kaggle/working/balanced dataset/Cabbage Loope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cabbage Loopers</td>\n",
       "      <td>/kaggle/working/balanced dataset/Cabbage Loope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cabbage Loopers</td>\n",
       "      <td>/kaggle/working/balanced dataset/Cabbage Loope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cabbage Loopers</td>\n",
       "      <td>/kaggle/working/balanced dataset/Cabbage Loope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3295</th>\n",
       "      <td>Corn Earworms</td>\n",
       "      <td>/kaggle/working/balanced dataset/Corn Earworms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>Corn Earworms</td>\n",
       "      <td>/kaggle/working/balanced dataset/Corn Earworms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>Corn Earworms</td>\n",
       "      <td>/kaggle/working/balanced dataset/Corn Earworms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>Corn Earworms</td>\n",
       "      <td>/kaggle/working/balanced dataset/Corn Earworms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>Corn Earworms</td>\n",
       "      <td>/kaggle/working/balanced dataset/Corn Earworms...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                label                                               path\n",
       "0     Cabbage Loopers  /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "1     Cabbage Loopers  /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "2     Cabbage Loopers  /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "3     Cabbage Loopers  /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "4     Cabbage Loopers  /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "...               ...                                                ...\n",
       "3295    Corn Earworms  /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3296    Corn Earworms  /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3297    Corn Earworms  /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3298    Corn Earworms  /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3299    Corn Earworms  /kaggle/working/balanced dataset/Corn Earworms...\n",
       "\n",
       "[3300 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "for key in key_value.keys():\n",
    "    for j in key_value[key]:\n",
    "        df.append([key,path+'/'+key+'/'+j])\n",
    "df1 = pd.DataFrame(df,columns=('label','path'))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0322727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:51:30.801766Z",
     "iopub.status.busy": "2023-07-14T18:51:30.800880Z",
     "iopub.status.idle": "2023-07-14T18:51:30.808538Z",
     "shell.execute_reply": "2023-07-14T18:51:30.807661Z"
    },
    "papermill": {
     "duration": 0.027517,
     "end_time": "2023-07-14T18:51:30.810549",
     "exception": false,
     "start_time": "2023-07-14T18:51:30.783032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "1       /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "2       /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "3       /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "4       /kaggle/working/balanced dataset/Cabbage Loope...\n",
       "                              ...                        \n",
       "3295    /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3296    /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3297    /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3298    /kaggle/working/balanced dataset/Corn Earworms...\n",
       "3299    /kaggle/working/balanced dataset/Corn Earworms...\n",
       "Name: path, Length: 3300, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c4b4e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:51:30.846046Z",
     "iopub.status.busy": "2023-07-14T18:51:30.845190Z",
     "iopub.status.idle": "2023-07-14T18:52:17.772122Z",
     "shell.execute_reply": "2023-07-14T18:52:17.771083Z"
    },
    "papermill": {
     "duration": 46.947178,
     "end_time": "2023-07-14T18:52:17.774472",
     "exception": false,
     "start_time": "2023-07-14T18:51:30.827294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Western Corn Rootworms/aug-112-Image_64.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Western Corn Rootworms/Image_35.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Western Corn Rootworms/aug-91-Image_35.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Western Corn Rootworms/Image_64.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Western Corn Rootworms/aug-42-Image_64.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Western Corn Rootworms/aug-21-Image_35.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Corn Borers/aug-118-Image_4.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Corn Borers/Image_4.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Corn Borers/aug-38-Image_4.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fall Armyworms/Image_68.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fall Armyworms/aug-57-Image_68.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fall Armyworms/aug-136-Image_68.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Africanized Honey Bees (Killer Bees)/Image_23.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Africanized Honey Bees (Killer Bees)/aug-19-Image_23.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Africanized Honey Bees (Killer Bees)/aug-86-Image_23.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fruit Flies/aug-150-Image_116.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fruit Flies/Image_116.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fruit Flies/aug-10-Image_116.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/balanced dataset/Fruit Flies/aug-80-Image_116.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for path, label in zip(df1['path'], df1['label']):\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (250, 200))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        #img = img.resize((300, 300 * img.shape[1] // img.shape[0]), Image.ANTIALIAS)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Image at path {path} is None\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or resizing image at path: {path}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "\n",
    "train_images = np.array(images, dtype='int')\n",
    "labels = np.array(labels)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels = le.fit_transform(labels)\n",
    "\n",
    "# Split the data into training and testing\n",
    "#train_images, test_images, train_labels, test_labels = train_test_split(images, y_labels, test_size=0.3, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8102bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:52:17.812094Z",
     "iopub.status.busy": "2023-07-14T18:52:17.811750Z",
     "iopub.status.idle": "2023-07-14T18:52:23.699155Z",
     "shell.execute_reply": "2023-07-14T18:52:23.698176Z"
    },
    "papermill": {
     "duration": 5.909198,
     "end_time": "2023-07-14T18:52:23.701847",
     "exception": false,
     "start_time": "2023-07-14T18:52:17.792649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Increase input image size\n",
    "base_model = keras.applications.ResNet50(\n",
    "    weights='imagenet', include_top=False, input_shape=(200, 250, 3)\n",
    ")\n",
    "fine_tune_at = 150\n",
    "\n",
    "# Adjust fine-tuning strategy\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(200, 250, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Use ReLU activation instead of sigmoid\n",
    "x = layers.Dense(1024, activation='sigmoid')(x)\n",
    "\n",
    "# Add dropout for regularization\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Adjust the number of units in the dense layer\n",
    "x = layers.Dense(512, activation='sigmoid')(x)\n",
    "\n",
    "# Add another dropout layer\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "outputs = layers.Dense(15, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Adjust learning rate and use learning rate schedule if needed\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb6d77f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:52:23.742000Z",
     "iopub.status.busy": "2023-07-14T18:52:23.741672Z",
     "iopub.status.idle": "2023-07-14T18:54:44.719965Z",
     "shell.execute_reply": "2023-07-14T18:54:44.719055Z"
    },
    "papermill": {
     "duration": 141.00073,
     "end_time": "2023-07-14T18:54:44.722199",
     "exception": false,
     "start_time": "2023-07-14T18:52:23.721469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "52/52 [==============================] - 26s 158ms/step - loss: 2.3919 - accuracy: 0.2566\n",
      "Epoch 2/15\n",
      "52/52 [==============================] - 8s 145ms/step - loss: 1.2372 - accuracy: 0.6739\n",
      "Epoch 3/15\n",
      "52/52 [==============================] - 8s 149ms/step - loss: 0.5791 - accuracy: 0.8711\n",
      "Epoch 4/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.2998 - accuracy: 0.9381\n",
      "Epoch 5/15\n",
      "52/52 [==============================] - 8s 148ms/step - loss: 0.1859 - accuracy: 0.9637\n",
      "Epoch 6/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.1328 - accuracy: 0.9729\n",
      "Epoch 7/15\n",
      "52/52 [==============================] - 8s 148ms/step - loss: 0.0902 - accuracy: 0.9854\n",
      "Epoch 8/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.0814 - accuracy: 0.9826\n",
      "Epoch 9/15\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 0.0652 - accuracy: 0.9878\n",
      "Epoch 10/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.0516 - accuracy: 0.9918\n",
      "Epoch 11/15\n",
      "52/52 [==============================] - 8s 147ms/step - loss: 0.0456 - accuracy: 0.9921\n",
      "Epoch 12/15\n",
      "52/52 [==============================] - 8s 151ms/step - loss: 0.0435 - accuracy: 0.9924\n",
      "Epoch 13/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.0413 - accuracy: 0.9924\n",
      "Epoch 14/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.0334 - accuracy: 0.9918\n",
      "Epoch 15/15\n",
      "52/52 [==============================] - 8s 146ms/step - loss: 0.0326 - accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78eb35d7bd30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Fit the model\n",
    "# Fit the model\n",
    "model.fit(train_images, train_labels, epochs=15, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ece3e6a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:54:44.885298Z",
     "iopub.status.busy": "2023-07-14T18:54:44.884404Z",
     "iopub.status.idle": "2023-07-14T18:54:55.551152Z",
     "shell.execute_reply": "2023-07-14T18:54:55.550164Z"
    },
    "papermill": {
     "duration": 10.74917,
     "end_time": "2023-07-14T18:54:55.554194",
     "exception": false,
     "start_time": "2023-07-14T18:54:44.805024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading or resizing image at path: /kaggle/working/dataset/test/Western Corn Rootworms/Image_27.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/dataset/test/Fall Armyworms/Image_81.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/dataset/test/Fall Armyworms/Image_40.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/dataset/test/Armyworms/Image_49.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/dataset/test/Aphids/Image_115.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "Error reading or resizing image at path: /kaggle/working/dataset/test/Spider Mites/Image_62.gif\n",
      "Error message: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path1 = '/kaggle/working/dataset/test'\n",
    "key_value= dict()\n",
    "for i in os.listdir(path1):\n",
    "    key_value[i] = os.listdir(path1+'/'+i)\n",
    "    \n",
    "df2 = []\n",
    "for key in key_value.keys():\n",
    "    for j in key_value[key]:\n",
    "        df2.append([key,path1+'/'+key+'/'+j])\n",
    "df2 = pd.DataFrame(df2,columns=('label','path'))\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for path, label in zip(df2['path'], df2['label']):\n",
    "    try:\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (250, 200))\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "        #img = img.resize((300, 300 * img.shape[1] // img.shape[0]), Image.ANTIALIAS)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            print(f\"Image at path {path} is None\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or resizing image at path: {path}\")\n",
    "        print(f\"Error message: {str(e)}\")\n",
    "\n",
    "test_images = np.array(images, dtype='int')\n",
    "labels = np.array(labels)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "test_labels = le.fit_transform(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0af9832c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:54:55.720511Z",
     "iopub.status.busy": "2023-07-14T18:54:55.720148Z",
     "iopub.status.idle": "2023-07-14T18:55:00.495821Z",
     "shell.execute_reply": "2023-07-14T18:55:00.494856Z"
    },
    "papermill": {
     "duration": 4.863115,
     "end_time": "2023-07-14T18:55:00.497797",
     "exception": false,
     "start_time": "2023-07-14T18:54:55.634682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 104ms/step\n",
      "Accuracy: 0.7217573221757322\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.predict(test_images)\n",
    "\n",
    "# Convert the predictions to the class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute the accuracy score\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a264a37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:55:00.663962Z",
     "iopub.status.busy": "2023-07-14T18:55:00.663550Z",
     "iopub.status.idle": "2023-07-14T18:55:00.674903Z",
     "shell.execute_reply": "2023-07-14T18:55:00.673803Z"
    },
    "papermill": {
     "duration": 0.095873,
     "end_time": "2023-07-14T18:55:00.677056",
     "exception": false,
     "start_time": "2023-07-14T18:55:00.581183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 72.17573221757321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(test_labels, predicted_labels, average='micro')\n",
    "\n",
    "print('Precision:', precision*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fe0ac6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-14T18:55:00.846141Z",
     "iopub.status.busy": "2023-07-14T18:55:00.845784Z",
     "iopub.status.idle": "2023-07-14T18:55:01.530509Z",
     "shell.execute_reply": "2023-07-14T18:55:01.529228Z"
    },
    "papermill": {
     "duration": 0.772902,
     "end_time": "2023-07-14T18:55:01.534570",
     "exception": false,
     "start_time": "2023-07-14T18:55:00.761668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('/kaggle/working/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d09e9b",
   "metadata": {
    "papermill": {
     "duration": 0.113578,
     "end_time": "2023-07-14T18:55:01.822429",
     "exception": false,
     "start_time": "2023-07-14T18:55:01.708851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 494.991018,
   "end_time": "2023-07-14T18:55:05.430214",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-14T18:46:50.439196",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
